{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect a candidate to develop a solution that is capable to classify provided texts in one of **four** classes.\n",
    " \n",
    "You may find the dataset in the **data** folder:\n",
    "- train.csv contains training dataset. There are four columns in this file:\n",
    "    - id - column with unique identifier of each data sample\n",
    "    - category - target variable\n",
    "    - title - document title\n",
    "    - description - document text\n",
    "- test.csv contains test dataset and all the columns are the same except category as it is unknown and should be predicted.\n",
    "- sample_submission.csv - an example of how resulting submission shoul look like.\n",
    "\n",
    "Your model should give as an output a probability of each sample belonging to each class.\n",
    "\n",
    "To submit your solution put this **solution.ipynb** file and generated **submission.csv** in a **zip** file.\n",
    "\n",
    "We are interested to see how candidate implements his/her typical pipeline to solve machine learning problems starting with a dataset containing both data and target variable.\n",
    "\n",
    "We **do not** expect a state-of-the-art solution here, rather a code that demonstrates candidate's understanding of crucial parts in ML models development. However, it would be a plus to see a brief description on how to get to the near-state-of-the-art solution in conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e45e61cb7f4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# add needed libraries here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReplaceDiatrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPunctRemove\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTfidf_fit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTfidf_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPreprocessText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import ReplaceDiatrics,PunctRemove,Tfidf_fit,Tfidf_transform,PreprocessText\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import auc, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your code in this and the following blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    31652\n",
       "True     26170\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = 100\n",
    "\n",
    "snoopes=pd.read_csv(\"data/snoopes.csv\")\n",
    "snoopes_test = snoopes.iloc[:test_data,:]\n",
    "snoopes = snoopes.iloc[test_data+1:,:]\n",
    "\n",
    "normal=pd.read_csv(\"data/normal.csv\")\n",
    "normal_test = normal.iloc[:test_data,:]\n",
    "normal = normal.iloc[test_data+1:,:]\n",
    "\n",
    "true_data=pd.read_csv(\"data/True.csv\")\n",
    "fake_data=pd.read_csv(\"data/Fake.csv\")\n",
    "\n",
    "del true_data['subject']\n",
    "del true_data['date']\n",
    "true_data['label'] = True\n",
    "true_data_test = true_data.iloc[:test_data,:]\n",
    "true_data = true_data.iloc[test_data+1:,:]\n",
    "\n",
    "del fake_data['subject']\n",
    "del fake_data['date']\n",
    "fake_data['label'] = False\n",
    "fake_data_test = fake_data.iloc[:test_data,:]\n",
    "fake_data = fake_data.iloc[test_data+1:,:]\n",
    "\n",
    "df = snoopes.append(normal).append(true_data).append(fake_data)\n",
    "test_df = snoopes_test.append(normal_test).append(true_data_test).append(fake_data_test)\n",
    "\n",
    "#check dataset balance\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Text Preprocessing Started-----\n",
      " ----Removing Stopwords---- \n",
      " ----Removing Diatrics---- \n",
      " ----Removing Punctuation---- \n",
      "-----Text Preprocessing Finished-----\n"
     ]
    }
   ],
   "source": [
    "#we will work with both texts together\n",
    "df[\"text_0\"]=df[\"title\"]+df[\"text\"]\n",
    "\n",
    "processed_df=PreprocessText(df)\n",
    "processed_df.head()\n",
    "\n",
    "X,y=processed_df.text_0,processed_df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Tfidf fitting-----\n",
      "-----Tfidf transforming-----\n"
     ]
    }
   ],
   "source": [
    "#train vectorizer and transform text\n",
    "Tfidf_fit(X)\n",
    "X=Tfidf_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score ->  0.9728755687569889\n"
     ]
    }
   ],
   "source": [
    "#select best hyperparameters\n",
    "\n",
    "SVM = SVC(kernel = 'linear', random_state = 0)\n",
    "'''\n",
    "SVM = Pipeline([('clf', SVC(random_state=1,C=10.0,probability=True))])\n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "param_grid = [{'clf__C': param_range,\n",
    "               'clf__kernel': ['linear']},\n",
    "              {'clf__C': param_range,\n",
    "               'clf__gamma': param_range,\n",
    "               'clf__kernel': ['rbf']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=SVM,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='f1_macro',\n",
    "                  cv=10,\n",
    "                  n_jobs=1)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print('--> Best score: ',gs.best_score_)\n",
    "print('--> Best parameters: \\n',gs.best_params_)\n",
    "\n",
    "\n",
    "#Select best parameters\n",
    "\n",
    "SVM = gs.best_estimator_\n",
    "'''\n",
    "#final values\n",
    "SVM.fit(X_train, y_train)\n",
    "\n",
    "# predict labels on validation set\n",
    "predictions_SVM = SVM.predict(X_test)\n",
    "\n",
    "# Use f1 score function \n",
    "print(\"F1 Score -> \",f1_score(y_test, predictions_SVM, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score ->  0.9718490983664321\n"
     ]
    }
   ],
   "source": [
    "# AUC metric\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predictions_SVM, pos_label=True)\n",
    "print(\"AUC Score -> \", auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6255   91]\n",
      " [ 219 5000]]\n"
     ]
    }
   ],
   "source": [
    "# Confussion matrix\n",
    "cm5 = confusion_matrix(y_test, predictions_SVM)\n",
    "print(cm5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##store model\n",
    "pickle.dump(SVM, open('svm.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Text Preprocessing Started-----\n",
      " ----Removing Stopwords---- \n",
      " ----Removing Diatrics---- \n",
      " ----Removing Punctuation---- \n",
      "-----Text Preprocessing Finished-----\n",
      "-----Tfidf transforming-----\n",
      "F1 Score ->  0.9123021316846135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[173,  35],\n",
       "       [  0, 192]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST DATA\n",
    "# fake_data=pd.read_csv(\"data/Fake.csv\")\n",
    "# true_data=pd.read_csv(\"data/True.csv\")\n",
    "# fake_data['label'] = False\n",
    "# true_data['label'] = True\n",
    "# test_df = fake_data.append(true_data)\n",
    "\n",
    "# test_df=pd.read_csv(\"data/snoopes.csv\")\n",
    "# test_df=pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# test_df = pd.DataFrame(columns=['title', 'text', 'label'])\n",
    "# obj = {}\n",
    "# obj['title']=\"For vaccine rates among Americans 65 and older, “there’s virtually no difference between white, Black, Hispanic, Asian American.”\"\n",
    "# obj['text']=\"During May 3 remarks on the American Families Plan, President Joe Biden boasted that there was not much disparity in the Covid-19 vaccination rates for white Americans and Americans of color who are at least 65.\\n\\n\\\"And what’s happening now is all the talk about how people were not going to get shots, they were not going to be involved — look at what that was — we were told that was most likely to be among people over 65 years of age,\\\" said Biden. \\\"But now people over 65 years of age, over 80%, have now been vaccinated, and 66% fully vaccinated. And there’s virtually no difference between white, Black, Hispanic, Asian American.\\\"\\n\\nThis isn’t the only time that Biden has made the claim.\\n\\nHe went even further on April 27 during remarks on the Covid-19 response: \\\"And, by the way, based on reported data, the proportion — the proportion of seniors who have been vaccinated is essentially equal between white and seniors of color. … As a matter of a fact, if I’m not mistaken, there are more Latinos and African American seniors that have been vaccinated, as a percentage, than white seniors.\\\"\\n\\nHowever, the national data that Biden keeps touting — vaccination statistics regarding both race and age — is not public. We asked the White House for the information underlying this claim, but officials did not provide specifics.\\n\\nSo, we moved on to the Centers for Disease Control and Prevention. Spokesperson Chandra Zeikel told KHN-PolitiFact on May 6 that \\\"unfortunately, we don’t have available a data breakdown of both racial demographics and age together.\\\" Zeikel didn’t respond to a follow-up question asking when or if the CDC would be publishing this data, but current CDC vaccination data is broken down only by race/ethnicity and shows significant differences, with white Americans far outpacing the percentage of other groups getting a shot. It also shows that the rate of vaccinations among some groups, including Black and Latino Americans, does not match their share of the population, though new CDC data shows there has been some progress on this front in the last two weeks.\\n\\nThat made us wonder about the premise of Biden’s statement. We turned to experts for their take.\\n\\n\\\"As far as I know, there is no comprehensive publicly available data on vaccination rates by race/ethnicity and age,\\\" Samantha Artiga, vice president and director of the racial equity and health policy program at KFF, wrote in an email. \\\"As such, we are not able to assess whether there are racial disparities in vaccinations among people over 65 years of age.\\\"\\n\\nWhat about other state-level data or anecdotes that might support Biden’s claim? Let’s dive in and see.\"\n",
    "# obj['label']=False\n",
    "# test_df = test_df.append(obj, ignore_index=True)\n",
    "\n",
    "test_df['label'].value_counts()\n",
    "\n",
    "test_df[\"text_0\"]=test_df[\"title\"]+test_df[\"text\"]\n",
    "\n",
    "processed_test_df=PreprocessText(test_df)\n",
    "X_t=processed_test_df.text_0\n",
    "X_t=Tfidf_transform(X_t)\n",
    "\n",
    "svm_model=pickle.load(open('svm.sav', 'rb'))\n",
    "\n",
    "predicted_cat=svm_model.predict(X_t)\n",
    "test_df[\"pred_label\"]=predicted_cat\n",
    "\n",
    "print(\"F1 Score -> \",f1_score(test_df[\"label\"], test_df[\"pred_label\"], average='macro'))\n",
    "confusion_matrix(test_df[\"label\"],test_df[\"pred_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=prob_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit the following code to generate a submission file\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = test_df['id']\n",
    "submission['category_0'] = predictions[:, 0]\n",
    "submission['category_1'] = predictions[:, 1]\n",
    "submission['category_2'] = predictions[:, 2]\n",
    "submission['category_3'] = predictions[:, 3]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colnclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a few words about your solution here. \n",
    "\n",
    "I developed a text classification pipeline that includes training a TFIDF model to vectorize text prior to training the linear SVM model. Text processing is crucial to get good results. I did not apply stemming or lemmatization as text quality is good as is and sometimes it can be counterproductive.\n",
    "\n",
    "- What could be improved? \n",
    "\n",
    "Hyperparameter tunning could be done with a wider range of values and the whole dataset. Instead of Grid search, Bayesian Optimization could be used.\n",
    "\n",
    "- What approaches may work as well for this problem? \n",
    "\n",
    "Convolutional Neural Networks, Random Forest, Naive Bayes, vectorizers: Bag of Words, Word embeddings\n",
    "\n",
    "- What would you implement if you have had more time for this task?\n",
    "\n",
    "A CNN\n",
    "\n",
    "- Feel free to write anything you think is relevant to this task :)\n",
    "\n",
    " I applied Grid Search for parameter tunning with a subset of data (for time and memory matters) to select parameter 'C'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "4a204b928366b526ae287d3cf12f408e35094248420feaf97acfeade00ab65f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}